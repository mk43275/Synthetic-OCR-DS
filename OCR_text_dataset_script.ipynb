{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script for Text OCR using OpenAI API\n",
    "---\n",
    "[OpenAI API documentation](https://platform.openai.com/docs/api-reference/introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv # load .env file for obtaining api key\n",
    "from openai import OpenAI      # text generation\n",
    "import pandas as pd            # save generated text as csv\n",
    "import re                      # regex for cleaning text\n",
    "import random      \n",
    "\n",
    "load_dotenv()  # config .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def generate_OCR_text_shopping(given_text, max_tokens = 6):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Output something that is found in a store from the given broad category. I just want the item name, \n",
    "            be thorough with your output.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given shopping category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_OCR_text_food_dishes(given_text, max_tokens = 6):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Your job is just to output me a some food or dish name from a broad food/dish category that I will provide.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given food/dish category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_OCR_text_titles(given_text, max_tokens = 12):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\" Your job is just to output me a specific title from a broad type of medium category that I will provide.\n",
    "            This title can either be some famous title or a made up one pertaining to the given category. Try not to pick or make long \n",
    "            titles.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given medium category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# functions used to clean up the generated text (aka output)\n",
    "def remove_quotation_marks(response_output):\n",
    "    return response_output.replace('\"', '')\n",
    "\n",
    "def remove_delimiters(response_output):\n",
    "    response_output = response_output.replace('\\n', '')\n",
    "    response_output = response_output.replace('\\\\', '')\n",
    "    return response_output\n",
    "\n",
    "def clean_text(response_output, title=False):\n",
    "    # remove emojis (if any)\n",
    "    response_output = re.sub(r'[^\\w\\s,]', '', response_output)\n",
    "\n",
    "    # remove specific punctuation (in this case, a period)\n",
    "    response_output = response_output.replace('.', '')\n",
    "\n",
    "    # if not a title, convert text to lowercase\n",
    "    if not title:\n",
    "        response_output = response_output.lower()\n",
    "\n",
    "    return response_output\n",
    "\n",
    "# store the generated text in lists\n",
    "shopping_goods_entries = list()\n",
    "food_dishes_entries = list()\n",
    "medium_entries = list()\n",
    "\n",
    "# categories for shopping, food and dishes, and title types\n",
    "shopping_goods_categories = [\n",
    "    \"Groceries\", \"Fresh Produce\", \"Dairy Products\", \"Bakery\", \"Meat and Poultry\",\n",
    "    \"Seafood\", \"Frozen Foods\", \"Canned Goods\", \"Snacks\", \"Sweets\",\n",
    "    \"Beverages\", \"Household Items\", \"Cleaning Supplies\", \"Laundry Supplies\", \"Kitchen Essentials\",\n",
    "    \"Skincare\", \"Haircare\", \"Oral Care\", \"Bath and Body\", \"Health and Wellness Products\", \"Clothing and Accessories\",\n",
    "    \"Men's Clothing\", \"Women's Clothing\", \"Children's Clothing\", \"Shoes\", \"Jewelry and Accessories\",\n",
    "    \"Electronics\", \"Televisions\", \"Computers and Laptops\", \"Mobile Phones\", \"Cameras\",\n",
    "    \"Audio Equipment\", \"Home and Furniture\", \"Living Room Furniture\", \"Bedroom Furniture\", \"Kitchen and Dining Furniture\",\n",
    "    \"Home DÃ©cor\", \"Bedding and Linens\", \"Toys\", \"Action Figures\", \"Board Games\",\n",
    "    \"Puzzles\", \"Outdoor Toys\", \"Automotive\", \"Car Maintenance Products\", \"Tires\",\n",
    "    \"Car Accessories\", \"Tools and Equipment\", \"Outdoor Equipment\", \"Sporting Goods\", \"Fitness Equipment\",\n",
    "    \"Outdoor Gear\", \"Bicycles\", \"Garden and Patio\", \"Gardening Tools\", \"Outdoor Furniture\",\n",
    "    \"Plants and Seeds\", \"Grills and Outdoor Cooking\", \"Pharmacy\", \"Prescription Medications\", \"Over-the-Counter Medications\",\n",
    "    \"Vitamins and Supplements\", \"Office Supplies\", \"Office Furniture\", \"School Supplies\", \"Pet Supplies\",\n",
    "    \"Pet Food\", \"Pet Toys\", \"Pet Health Products\", \"Pet Accessories\", \"Consoles\"\n",
    "]\n",
    "\n",
    "food_and_dishes_categories = [\n",
    "    \"Fruits\", \"Vegetables\", \"Dairy Products\", \"Meat and Poultry\", \"Seafood\",\n",
    "    \"Bakery\", \"Frozen Foods\", \"Canned Goods\", \"Beverages\", \"Grains and Pasta\",\n",
    "    \"Cereals\", \"Condiments and Sauces\", \"Spices and Herbs\", \"Nuts and Seeds\", \"Soups and Broths\",\n",
    "    \"Oils and Vinegars\", \"Health Foods\", \"Baby Food\", \"Breakfast Foods\", \"Mexican Dishes\",\n",
    "    \"American Dishes\", \"Argentinian Dishes\", \"Indian Dishes\", \"Chinese Dishes\", \"Japanese Dishes\",\n",
    "    \"Italian Dishes\", \"French Dishes\", \"German Dishes\", \"Greek Dishes\", \"Korean Dishes\",\n",
    "    \"Thai Dishes\", \"Vietnamese Dishes\", \"Spanish Dishes\", \"Brazilian Dishes\", \"Middle Eastern Dishes\",\n",
    "    \"African Dishes\", \"Caribbean Dishes\", \"Deli Meats\", \"Cheese\", \"Ice Cream and Desserts\"\n",
    "]\n",
    "\n",
    "medium_types = [\n",
    "    \"Books\", \"Movies\", \"TV Shows\", \"Songs\", \"Albums\",\n",
    "    \"Paintings\", \"Poems\", \"Plays\", \"Video Games\", \"Podcasts\",\n",
    "    \"Websites\", \"Magazines\", \"Academic Journals\", \"Newspapers\", \"Comics\"\n",
    "]\n",
    "\n",
    "def gen_clean_OCR_output(output_size, categories):\n",
    "    output_text_list = list()\n",
    "    while len(output_text_list) < output_size:\n",
    "        # randomly choose a category from given category list\n",
    "        category = random.choice(categories)\n",
    "        response = generate_OCR_text_shopping(category)\n",
    "\n",
    "        # clean up the output\n",
    "        response = remove_quotation_marks(response)\n",
    "        response = remove_delimiters(response)\n",
    "        response = clean_text(response)\n",
    "\n",
    "        # make sure we don't have duplicates\n",
    "        if response not in input:\n",
    "            input.append(response)\n",
    "\n",
    "    return output_text_list\n",
    "\n",
    "shopping_goods_texts = gen_clean_OCR_output(5000, shopping_goods_categories)\n",
    "food_dishes_texts = gen_clean_OCR_output(2500, food_and_dishes_categories)\n",
    "title_texts = gen_clean_OCR_output(2500, medium_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at text outputs\n",
    "print(f\"Shopping Good Data Entries (size: {len(shopping_goods_texts)}):\")\n",
    "print(shopping_goods_texts)\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Food and Dishes Data Entries (size: {len(food_dishes_texts)}):\")\n",
    "print(food_dishes_texts)\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Title Data Entries (size: {len(title_texts)}):\")\n",
    "print(title_texts)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conglomerated_data = []\n",
    "\n",
    "# join all the generated text entries along with their respective categories\n",
    "for entry in shopping_goods_entries:\n",
    "    conglomerated_data.append({\"OCR Text\": entry, \"Category\": \"Shopping Goods\"})\n",
    "\n",
    "for entry in food_dishes_entries:\n",
    "    conglomerated_data.append({\"OCR Text\": entry, \"Category\": \"Food/Dishes\"})\n",
    "\n",
    "for entry in medium_entries:\n",
    "    conglomerated_data.append({\"OCR Text\": entry, \"Category\": \"Title Types\"})\n",
    "\n",
    "# create pandas df\n",
    "df = pd.DataFrame(conglomerated_data)\n",
    "\n",
    "# save as a csv file\n",
    "df.to_csv('OCR_text_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
